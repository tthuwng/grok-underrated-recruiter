{
  "handle": "JunlinWang3",
  "bio": "PhD @duke_nlp. Intern @togethercompute @googledeepmind",
  "followers": 265,
  "technical_depth": {
    "score": 10,
    "evidence": "PhD Duke NLP, first/co-author on multiple papers at EMNLP 2024 (3), ACL 2024 Findings, NAACL 2024 Findings, arXiv MoA (SOTA on AlpacaEval/MT-Bench with OSS LLMs); topics: LLM reasoning, inference scaling, alignment, security; Google Scholar 633 citations; interns Together AI (MoA), DeepMind"
  },
  "project_evidence": {
    "score": 7,
    "evidence": "GitHub https://github.com/IsThatYou (low public repos/activity); contributed to RaccoonBench (ACL code), Together's MoA repo; research projects with code from papers (e.g., budget-aware reasoning EMNLP, prompt extraction); no high-star OSS but quality research code"
  },
  "mission_alignment": {
    "score": 10,
    "evidence": "All X posts on frontier AI: LLM reasoning (o1-like, inference scaling, backtracking), alignment (MoA), agents, security (Raccoon); shares ICML/EMNLP papers; interns Together/DeepMind; obsessed with reasoning/scaling"
  },
  "exceptional_ability": {
    "score": 10,
    "evidence": "Novel contributions: MoA pipeline using OSS LLMs for SOTA alignment; inference scaling evals showing majority vote superior, non-reasoning can't match reasoning models; budget-aware metrics for reasoning strategies; prompt extraction benchmark; top interns solving hard LLM problems"
  },
  "communication": {
    "score": 10,
    "evidence": "Clear X threads with visuals/key findings (e.g., inference scaling plots, MoA ICML poster); well-organized personal site with pubs/CV; conference presentations (EMNLP/ICML); concise insightful replies (e.g., slop metric, RL modes)"
  },
  "final_score": 92.5,
  "summary": "Junlin Wang is an outstanding PhD candidate at Duke NLP with a strong track record of publications in top venues on LLM reasoning, alignment, and security, complemented by internships at elite labs like Together AI and DeepMind. His work demonstrates deep technical expertise and direct impact on frontier AI challenges. Ideal for research roles advancing xAI's reasoning capabilities.",
  "strengths": [
    "Prolific research output with SOTA results in LLM alignment/reasoning",
    "Elite internships and collaborations yielding high-impact papers",
    "633 citations at PhD stage"
  ],
  "concerns": [
    "Sparse public GitHub repositories",
    "Relatively low X visibility (265 followers)"
  ],
  "recommended_role": "research",
  "github_url": "https://github.com/IsThatYou",
  "linkedin_url": null,
  "top_repos": [
    "togethercomputer/MoA",
    "M0gician/RaccoonBench"
  ],
  "citations": [
    "https://github.com/hijkzzz/Awesome-LLM-Strawberry",
    "https://x.com/i/status/1914774586866196660",
    "https://x.com/i/user/2224217683",
    "https://x.com/i/status/1992059911627473339",
    "https://www.linknovate.com/search/?query=nick%2520lab%2520asst",
    "https://github.com/fscdc/Awesome-Efficient-Reasoning-Models",
    "https://x.com/JunlinWang3",
    "https://github.com/akjava/godot-groq-moa",
    "https://www.together.ai/blog/together-moa",
    "https://royxie.com/",
    "https://arxiv.org/html/2406.04692v1",
    "https://au.linkedin.com/in/junlin-wang-335033291",
    "https://scholar.google.com/citations?user=7D1e-A0AAAAJ&hl=en",
    "https://x.com/i/status/1805028095034036558",
    "https://github.com/akthom/ParatextsAndDocumentaryPractices/blob/master/AcksForFinalCoding.txt",
    "https://x.com/i/status/1990577951671509438",
    "https://scholar.google.com/citations?user=oTjABVkAAAAJ&hl=en",
    "https://x.com/i/status/1980676477005054170",
    "https://x.com/i/status/1990274892034642347",
    "https://dblp.org/pid/p/JianPei",
    "https://x.com/i/status/1856829303071060135",
    "https://x.com/i/status/1856829301708263533",
    "https://x.com/i/status/1989011602289328431",
    "https://github.com/amusi/ECCV2024-Papers-with-Code/blob/master/ECCV2022-Papers-with-Code.md",
    "https://x.com/i/status/1945207089976017407",
    "https://x.com/i/status/1805028093763228121",
    "https://scholar.google.com/citations?user=7D1e-A0AAAAJ&hl=vi",
    "https://x.com/i/status/1989854202147832191",
    "https://x.com/i/status/1980497393209725271",
    "https://github.com/Machine-Learning-Tokyo/ML_Fairness_Ethics_Explainability",
    "https://github.com/M0gician/RaccoonBench",
    "https://x.com/i/status/1991527921316773931",
    "https://x.com/i/status/1799986416077951460",
    "https://github.com/inpluslab-wuhui/Systems-for-Foundation-Models",
    "https://x.com/duke_nlp",
    "https://x.com/i/status/1989051238818935214",
    "https://x.com/i/status/1914774592821788901",
    "https://x.com/i/status/1987787127204249824",
    "https://x.com/i/status/1930149228812349634",
    "https://www.linkedin.com/pulse/mixture-agents-moa-new-frontier-shiftavenue-uzgde",
    "https://x.com/i/status/1980407800850473172",
    "https://x.com/i/status/1914774589348905173",
    "https://x.com/i/status/1856829298692558915",
    "https://x.com/i/status/1990463392717385949",
    "https://x.com/i/status/1992380988593443016",
    "https://x.com/i/status/1863297443745427948",
    "https://github.com/hemingkx/Awesome-Efficient-Reasoning",
    "https://x.com/i/status/1992053281900941549",
    "https://github.com/juand-r/EMNLP-2020",
    "https://x.com/i/status/1914774584584266192",
    "https://scholar.google.com/citations?user=TPnedXMAAAAJ&hl=en",
    "https://github.com/togethercomputer/MoA",
    "https://ca.linkedin.com/in/junlin-wang-3786a3257",
    "https://github.com/NY1024/Awesome-Trustworthy-GenAI",
    "https://x.com/i/status/1863297446882762905",
    "https://it.linkedin.com/in/junlin-wang-7a2512184",
    "https://x.com/i/status/1992310971834982716",
    "https://x.com/i/status/1992403104768418291",
    "https://www.linkedin.com/in/harish-chandran-usa",
    "https://sameersingh.org/group.html",
    "https://dl.acm.org/doi/abs/10.1145/3711896.3736884",
    "https://ca.linkedin.com/in/junlin-wang/zh-tw",
    "https://x.com/i/status/1973435013875314729",
    "https://x.com/i/status/1863297445251178696",
    "http://aclrollingreview.org/people",
    "https://x.com/i/status/1927789776444272884",
    "https://x.com/i/status/1992437287058321874",
    "https://medium.com/%40shrimangalevallabh789/mixture-of-agents-enhances-large-language-model-capabilities-c817654f4a52",
    "https://x.com/i/status/1988559900117459217",
    "https://x.com/i/status/1882156217315045836",
    "https://x.com/i/status/1988827262825718129",
    "https://x.com/i/status/1988665013410898019",
    "https://x.com/i/status/1805028097781330263",
    "https://github.com/ucinlp/facade",
    "https://cs.duke.edu/phd-program",
    "https://scholar.google.com/citations?user=PykI8xcAAAAJ&hl=en",
    "https://github.com/skapadia3214/groq-moa",
    "https://github.com/kevint-cerebras/cerebras-moa",
    "https://x.com/i/status/1992437283795161265",
    "https://github.com/Atomic-man007/Awesome_Multimodel_LLM",
    "https://x.com/i/status/1987761156409192702",
    "https://scholar.google.com/citations?user=gH3HsTkAAAAJ&hl=en",
    "https://x.com/i/status/1987934460252217474",
    "https://www.linkedin.com/in/lalitha-nallamothula-0b7a1381",
    "https://x.com/i/status/1989670948807770367",
    "https://x.com/i/status/1863297442424225852",
    "https://www.linkedin.com/in/satyanadh-g",
    "https://github.com/IsThatYou",
    "https://cn.linkedin.com/in/junlin-wang-950820221",
    "https://x.com/i/status/1988810306437673413",
    "https://x.com/i/status/1992381094667411768",
    "https://x.com/i/status/1805028096120402000",
    "https://x.com/i/status/1990141050640540123",
    "https://x.com/i/status/1974169721831632981",
    "https://x.com/i/status/1988829729894412574",
    "https://github.com/Hsword/Awesome-Machine-Learning-System-Papers",
    "https://x.com/i/status/1914774591110623239",
    "https://ca.linkedin.com/in/nicholas-l%25C3%25A9onard",
    "https://x.com/i/status/1930092880925692309",
    "https://arxiv.org/html/2408.13296v1",
    "https://papers.ssrn.com/sol3/Delivery.cfm/5381584.pdf?abstractid=5381584&mirid=1",
    "https://openreview.net/profile?id=~Junlin_Wang1",
    "https://scholar.google.com/citations?user=s1Qw2pAAAAAJ&hl=en",
    "https://nlplab.cs.duke.edu/people/",
    "https://isthatyou.github.io/",
    "https://openreview.net/profile?id=~Paul_Rosu1"
  ],
  "raw_response": "{\n  \"technical_depth\": {\"score\": 10, \"evidence\": \"PhD Duke NLP, first/co-author on multiple papers at EMNLP 2024 (3), ACL 2024 Findings, NAACL 2024 Findings, arXiv MoA (SOTA on AlpacaEval/MT-Bench with OSS LLMs); topics: LLM reasoning, inference scaling, alignment, security; Google Scholar 633 citations; interns Together AI (MoA), DeepMind\"},\n  \"project_evidence\": {\"score\": 7, \"evidence\": \"GitHub https://github.com/IsThatYou (low public repos/activity); contributed to RaccoonBench (ACL code), Together's MoA repo; research projects with code from papers (e.g., budget-aware reasoning EMNLP, prompt extraction); no high-star OSS but quality research code\"},\n  \"mission_alignment\": {\"score\": 10, \"evidence\": \"All X posts on frontier AI: LLM reasoning (o1-like, inference scaling, backtracking), alignment (MoA), agents, security (Raccoon); shares ICML/EMNLP papers; interns Together/DeepMind; obsessed with reasoning/scaling\"},\n  \"exceptional_ability\": {\"score\": 10, \"evidence\": \"Novel contributions: MoA pipeline using OSS LLMs for SOTA alignment; inference scaling evals showing majority vote superior, non-reasoning can't match reasoning models; budget-aware metrics for reasoning strategies; prompt extraction benchmark; top interns solving hard LLM problems\"},\n  \"communication\": {\"score\": 10, \"evidence\": \"Clear X threads with visuals/key findings (e.g., inference scaling plots, MoA ICML poster); well-organized personal site with pubs/CV; conference presentations (EMNLP/ICML); concise insightful replies (e.g., slop metric, RL modes)\"},\n  \"summary\": \"Junlin Wang is an outstanding PhD candidate at Duke NLP with a strong track record of publications in top venues on LLM reasoning, alignment, and security, complemented by internships at elite labs like Together AI and DeepMind. His work demonstrates deep technical expertise and direct impact on frontier AI challenges. Ideal for research roles advancing xAI's reasoning capabilities.\",\n  \"strengths\": [\"Prolific research output with SOTA results in LLM alignment/reasoning\", \"Elite internships and collaborations yielding high-impact papers\", \"633 citations at PhD stage\"],\n  \"concerns\": [\"Sparse public GitHub repositories\", \"Relatively low X visibility (265 followers)\"],\n  \"recommended_role\": \"research\",\n  \"github_url\": \"https://github.com/IsThatYou\",\n  \"linkedin_url\": null,\n  \"top_repos\": [\"togethercomputer/MoA\", \"M0gician/RaccoonBench\"]\n}"
}