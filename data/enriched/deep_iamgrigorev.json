{
  "handle": "iamgrigorev",
  "bio": "now: exploring opensource; prev: training @togethercompute, chatbots&diffusion@snap rare specialty coffee lover",
  "followers": 2803,
  "technical_depth": {
    "score": 8,
    "evidence": "Deep discussions on MoE training dynamics (decoupled FFN, data rephrasing), FP8/NVFP4 stability (muP, bungee scalars, no grad clip), tokenizers (SuperBPE for 20% sample efficiency), normalizations (QK-Norm, LayerNorm scaling); implements DDP/FSDP/TP from scratch; ablations on schedules, optimizers."
  },
  "project_evidence": {
    "score": 8,
    "evidence": "https://github.com/thepowerfuldeez/sample_efficient_gpt (70M model <20 perplexity on single GPU in 5h); Rust BPE/tokenizer tools; Mixture-of-Depths impl (10% speed, memory savings); FP8 training plans; shipped products at Snap (chatbots/diffusion), Together AI (training)."
  },
  "mission_alignment": {
    "score": 9,
    "evidence": "Frequent posts on frontier LLM training (DeepSeek V3/V3.2, OLMo, Qwen), open-source optimizations, MoE/RLHF/post-training; exploring sample-efficient GPTs, consumer GPU scaling."
  },
  "exceptional_ability": {
    "score": 8,
    "evidence": "Solves hard problems like FP8 MoE stability on limited hardware, SuperBPE cross-word merges, efficient single-GPU training; unique insights on activation kurtosis, cautious WD; ownership in personal repos/ablations; ex-Snap/Together scale experience."
  },
  "communication": {
    "score": 9,
    "evidence": "Detailed X threads (e.g., FP8 normalizations, tokenizer principles); blog https://ggrigorev.me/posts/tokenizer-superbpe/ with plots/code; clear explanations of complex topics like GRPO/KL fixes."
  },
  "final_score": 83.0,
  "summary": "George Grigorev is a skilled ML engineer with production experience at Snap and Together AI, now focused on open-source LLM training optimizations like efficient tokenizers and low-precision stability. Strong on practical engineering for scalable, sample-efficient models on consumer hardware.",
  "strengths": [
    "Hands-on training optimizations (FP8, MoE, tokenizers)",
    "Open-source contributions and clear technical communication"
  ],
  "concerns": [
    "Limited evidence of massive-scale projects or peer-reviewed papers",
    "Repos not yet at 1k+ stars"
  ],
  "recommended_role": "engineering",
  "github_url": "https://github.com/thepowerfuldeez",
  "linkedin_url": "https://uk.linkedin.com/in/george-grigorev",
  "top_repos": [
    "sample_efficient_gpt",
    "LayerNorm-Scaling"
  ],
  "citations": [
    "https://www.linkedin.com/in/ziwen-wang",
    "https://x.com/i/status/1988271727466692639",
    "https://x.com/i/status/1995469120100606451",
    "https://x.com/i/status/1995887410274529562",
    "https://x.com/i/status/1982913510901219495",
    "https://x.com/i/status/1981731321350099010",
    "https://x.com/i/status/1993940294287647029",
    "https://x.com/i/status/1994501677177532702",
    "https://x.com/i/status/1996134822612230193",
    "https://x.com/i/status/1993906227731157498",
    "https://x.com/i/status/1995461255788625941",
    "https://x.com/iamgrigorev?lang=en",
    "https://forum.cloudron.io/topic/14068/how-to-use-local-gpu-with-remote-librechat",
    "https://www.reddit.com/r/LocalLLaMA/comments/1c14v49/olmo_mixtureofdepths_bitnet_run/",
    "https://x.com/i/status/1981091514370707946",
    "https://x.com/i/status/1993958593268486417",
    "https://x.com/i/status/1994506928651895235",
    "https://www.twstalker.com/yifan_zhang_",
    "https://x.com/i/status/1997180808504004710",
    "https://github.com/huggingface/open-r1/issues/100",
    "https://www.techmeme.com/241206/p18",
    "https://x.com/i/status/1996475355801284717",
    "https://x.com/i/status/1975562834793607464",
    "https://x.com/i/status/1995452751216624024",
    "https://uk.linkedin.com/in/george-grigorev/ru",
    "https://twstalker.com/xiangfu_ml",
    "https://x.com/i/status/1995197720936812975",
    "https://www.linkedin.com/posts/gianlucaventuri_ai-llm-openai-activity-7359289733253898244--0c0",
    "https://x.com/i/status/1995028811080155537",
    "https://x.com/i/status/1997181744173535633",
    "https://x.com/i/status/1980601826304037135",
    "https://x.com/i/status/1997030187922522143",
    "https://x.com/i/status/1997576111199527157",
    "https://x.com/i/status/1997123628765524132",
    "https://x.com/i/status/1980598983845109773",
    "https://x.com/i/status/1996591448964186294",
    "https://www.techmeme.com/241206/p32",
    "https://twstalker.com/harshhpareek",
    "https://x.com/i/status/1981480034050126248",
    "https://x.com/i/status/1982914743183753721",
    "https://x.com/i/status/1996976702732620271",
    "https://x.com/i/status/1981824032489238950",
    "https://x.com/i/status/1993886652583039455",
    "https://x.com/i/status/1997458598885199994",
    "https://x.com/i/status/1993895082911756683",
    "https://x.com/i/status/1993880887973601587",
    "https://x.com/i/status/1996398732506710096",
    "https://www.linkedin.com/posts/theleokul_george-is-the-guy-who-introduced-me-to-snap-activity-7160354431673204736-EGEV",
    "https://x.com/i/status/1995464290430570907",
    "https://x.com/i/status/1995592664637665702",
    "https://x.com/i/status/1993913951323926821",
    "https://x.com/i/status/1993882074617688388",
    "https://uk.linkedin.com/in/george-grigorev",
    "https://news.ycombinator.com/item?id=44850260",
    "https://x.com/i/status/1996587860569284699",
    "https://www.linkedin.com/posts/snap-inc-co_snap-is-heading-to-kdd-2025-in-toronto-this-activity-7357435193336426496-YlZv",
    "https://x.com/i/status/1988271884153057311",
    "https://x.com/i/status/1993906370979221880",
    "https://x.com/i/status/1995493787876147538",
    "https://x.com/i/status/1981661580669624730",
    "https://github.com/lmsdss/LayerNorm-Scaling",
    "https://x.com/i/status/1975154768436711813",
    "https://twitter.com/iamgrigorev/status/1929613671602212986",
    "https://x.com/i/status/1997605704862249150",
    "https://x.com/i/status/1997604064100823138",
    "https://www.linkedin.com/posts/shubham-srivstv_7-github-repositories-that-will-help-you-activity-7311417553916948480-17if",
    "https://x.com/iamgrigorev/status/1949205342271001007",
    "https://twstalker.com/wondering_camel",
    "https://x.com/i/status/1980595515017630046",
    "https://x.com/i/status/1993895068290388134",
    "https://x.com/i/status/1993886334625419633",
    "https://x.com/i/status/1993898232158802103",
    "https://x.com/i/status/1980599931694903558",
    "https://x.com/i/status/1981756935847240148",
    "https://x.com/i/status/1996597995287290168",
    "https://x.com/i/status/1996386648226181394",
    "https://x.com/i/status/1994603265926004857",
    "https://x.com/i/status/1984336561471676794",
    "https://x.com/i/status/1995603730855854363",
    "https://x.com/i/status/1994603592649773441",
    "https://www.linkedin.com/in/rosiegao",
    "https://x.com/i/status/1996385840482951431",
    "https://x.com/i/status/1995653247978418439",
    "https://ngntipkolamrenang.twstalker.com/AAY1993",
    "https://x.com/i/status/1996398947955523883",
    "https://x.com/i/status/1982026283899838655",
    "https://twitter.com/iamgrigorev/status/1778479854922469465",
    "https://x.com/i/status/1996592155897512094",
    "https://x.com/i/status/1994505056042062095",
    "https://x.com/i/status/1996590077359882407",
    "https://x.com/i/status/1980599570699612631",
    "https://x.com/i/status/1997126533060903239",
    "https://x.com/i/status/1997071569311748162",
    "https://x.com/i/status/1993883750808350973",
    "https://x.com/i/status/1993962211333820902",
    "https://x.com/i/status/1997459906719547535",
    "https://twstalker.com/BlockFullLife",
    "https://x.com/i/status/1997604968916762663",
    "https://x.com/i/status/1995492947480158437",
    "https://x.com/i/status/1997530801316003912",
    "https://x.com/i/status/1984000679178854492",
    "https://x.com/i/status/1981390111989518809",
    "https://x.com/i/status/1996294728636313814",
    "https://x.com/i/status/1994352344507511199",
    "https://x.com/iamgrigorev/status/1997098852118335794",
    "https://x.com/i/status/1996591404710064498",
    "https://x.com/i/status/1981220131159364002",
    "https://x.com/i/status/1981091350536999345",
    "https://x.com/i/status/1981007946759942433",
    "https://x.com/i/status/1997605275210313970",
    "https://x.com/i/status/1776315668599574578",
    "https://x.com/i/status/1996583787543527579",
    "https://x.com/i/status/1981122989472006504",
    "https://www.linkedin.com/posts/george-grigorev_opentowork-layoff-layoffs-activity-7160286548553310209-7NFQ",
    "https://x.com/i/status/1997182058154938389",
    "https://x.com/i/status/1981265403209810285",
    "https://x.com/i/status/1995468547040932106",
    "https://x.com/i/status/1974794103021044001",
    "https://x.com/i/status/1997098852118335794",
    "https://x.com/i/status/1993951838283116950",
    "https://x.com/i/status/1995470191753310615",
    "https://x.com/i/status/1997030357657591927",
    "https://x.com/i/status/1976779890687869251",
    "https://x.com/i/status/1984262505443844263",
    "https://x.com/i/status/1981005208969986304"
  ],
  "raw_response": "{\n  \"technical_depth\": {\"score\": 8, \"evidence\": \"Deep discussions on MoE training dynamics (decoupled FFN, data rephrasing), FP8/NVFP4 stability (muP, bungee scalars, no grad clip), tokenizers (SuperBPE for 20% sample efficiency), normalizations (QK-Norm, LayerNorm scaling); implements DDP/FSDP/TP from scratch; ablations on schedules, optimizers.\"},\n  \"project_evidence\": {\"score\": 8, \"evidence\": \"https://github.com/thepowerfuldeez/sample_efficient_gpt (70M model <20 perplexity on single GPU in 5h); Rust BPE/tokenizer tools; Mixture-of-Depths impl (10% speed, memory savings); FP8 training plans; shipped products at Snap (chatbots/diffusion), Together AI (training).\"},\n  \"mission_alignment\": {\"score\": 9, \"evidence\": \"Frequent posts on frontier LLM training (DeepSeek V3/V3.2, OLMo, Qwen), open-source optimizations, MoE/RLHF/post-training; exploring sample-efficient GPTs, consumer GPU scaling.\"},\n  \"exceptional_ability\": {\"score\": 8, \"evidence\": \"Solves hard problems like FP8 MoE stability on limited hardware, SuperBPE cross-word merges, efficient single-GPU training; unique insights on activation kurtosis, cautious WD; ownership in personal repos/ablations; ex-Snap/Together scale experience.\"},\n  \"communication\": {\"score\": 9, \"evidence\": \"Detailed X threads (e.g., FP8 normalizations, tokenizer principles); blog https://ggrigorev.me/posts/tokenizer-superbpe/ with plots/code; clear explanations of complex topics like GRPO/KL fixes.\"},\n  \"summary\": \"George Grigorev is a skilled ML engineer with production experience at Snap and Together AI, now focused on open-source LLM training optimizations like efficient tokenizers and low-precision stability. Strong on practical engineering for scalable, sample-efficient models on consumer hardware.\",\n  \"strengths\": [\"Hands-on training optimizations (FP8, MoE, tokenizers)\", \"Open-source contributions and clear technical communication\"],\n  \"concerns\": [\"Limited evidence of massive-scale projects or peer-reviewed papers\", \"Repos not yet at 1k+ stars\"],\n  \"recommended_role\": \"engineering\",\n  \"github_url\": \"https://github.com/thepowerfuldeez\",\n  \"linkedin_url\": \"https://uk.linkedin.com/in/george-grigorev\",\n  \"top_repos\": [\"sample_efficient_gpt\", \"LayerNorm-Scaling\"]\n}"
}